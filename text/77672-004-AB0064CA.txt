Tensor analysis, branch of mathematics concerned with relations or laws that remain valid regardless of the system of coordinates used to specify the quantities. Such relations are called covariant. Tensors were invented as an extension of vectors to formalize the manipulation of geometric entities arising in the study of mathematical manifolds.
A vector is an entity that has both magnitude and direction; it is representable by a drawing of an arrow, and it combines with similar entities according to the parallelogram law. Because of that law, a vector has components—a different set for each coordinate system. When the coordinate system is changed, the components of the vector change according to a mathematical law of transformation deducible from the parallelogram law. This law of transformation of the components has two important properties. First, after a sequence of changes that end up in the original coordinate system, the components of the vector will be the same as at the start. Second, relationships among vectors—for example, three vectors U, V, W such that 2U + 5V = 4W—will be present in the components regardless of the coordinate system.